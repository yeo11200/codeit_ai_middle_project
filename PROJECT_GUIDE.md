# RAG ChatBot 프로젝트 개발 가이드 (Development Log & Technical Guide)

이 문서는 프로젝트의 개발 과정, 기술적 의사결정, 그리고 구현 세부 사항을 **개발 단계(Phase)** 별로 상세하게 기록한 기술 문서입니다.
단순한 사용법을 넘어, **"어떤 문제를 마주했고, 어떻게 해결했는가?"**에 초점을 맞추어 작성되었습니다.

---

## 📅 Phase 1: 기반 시스템 구축 (Foundation)

프로젝트 초기에는 다양한 입찰 공고(RFP) 문서를 처리하고, 이를 벡터화하여 검색할 수 있는 기본 파이프라인을 구축하는 데 집중했습니다.

### 1.1 데이터 파이프라인 (Data Pipeline)
RFP 문서는 주로 **HWP**와 **PDF** 형식으로 제공됩니다. 이를 텍스트로 변환하는 것이 첫과제였습니다.

-   **HWP 처리**: 초기엔 `olefile`을 사용했으나 텍스트 깨짐 현상이 심각했습니다. 이를 해결하기 위해 **`pyhwp` (hwp5txt)** 라이브러리를 서브프로세스(`subprocess`)로 호출하여 텍스트를 온전히 추출하는 방식을 채택했습니다.
-   **청킹(Chunking)**: `RecursiveCharacterTextSplitter`를 사용하여 문맥이 끊기지 않도록 1000자 단위로 자르고, 200자의 중복(`chunk_overlap`)을 두었습니다.

### 1.2 벡터 저장소 (Vector Store)
-   **Model**: `ChromaDB` (Serverless, 로컬 파일 기반)
-   **Embeddings**: OpenAI `text-embedding-3-small` (가성비 및 한국어 성능 우수)

---

## ⚙️ Phase 2: 검색 품질 고도화 (Advanced Retrieval)

기본 RAG만으로는 "정확한 예산 금액"이나 "특정 자격 요건"을 찾는 데 한계가 있었습니다. 이를 보완하기 위해 **하이브리드 검색**과 **리랭킹**을 도입했습니다.

### 2.1 하이브리드 검색 (Hybrid Search)
키워드 매칭(BM25)과 의미 검색(Vector)의 장점을 결합했습니다.
-   **BM25**: "10억원", "자바" 같은 구체적인 키워드 검색에 강함.
-   **Vector**: "시스템 구축 경험" 같은 문맥적 의미 검색에 강함.
-   **Ensemble**: `EnsembleRetriever`를 사용하여 두 검색 결과의 가중치를 5:5로 혼합했습니다.

### 2.2 리랭킹 (Re-ranking)
검색된 문서들의 관련성 점수를 다시 계산하여 순위를 재조정하는 기술입니다.
-   **Model**: `FlashRank` (경량화된 Cross-Encoder 모델 사용)
-   **Process**:
    1.  1차 검색에서 문서 **10개** 후보 추출.
    2.  FlashRank가 질문과 문서 간의 연관성을 정밀 채점.
    3.  상위 **3개(`top_k=3`)** 문서만 최종 선별하여 LLM에게 전달.
    > *결과: 엉뚱한 문서를 참고하여 환각(Hallucination)을 일으키는 빈도가 현저히 줄어듦.*

---

## 🧠 Phase 3: 생성 모델 & 프롬프트 최적화 (Generation)

사용자 경험(UX)을 결정짓는 답변 생성 단계에서의 최적화 작업입니다.

### 3.1 LLM 모델 선정
-   **Model**: **OpenAI `gpt-5-mini`**
-   **이유**: `gpt-4o` 대비 속도가 빠르고 비용이 저렴하며, RAG 태스크에 충분한 성능을 보여줌.
-   **설정**: `temperature=0` (창의성을 배제하고 사실 기반 답변 유도)

### 3.2 시스템 프롬프트 엔지니어링
한국어 문서 처리에 특화된 페르소나를 부여했습니다.

```python
system_prompt = """당신은 제안요청서(RFP) 문서를 분석하는 전문 어시스턴트입니다.
제공된 문맥(Context)에 기반하여 사용자의 질문에 답변하세요.
만약 문맥에서 답을 찾을 수 없다면 "제공된 문서 내용에서 찾을 수 없습니다."라고 답하세요.
답변은 공손하고 전문적인 어조의 한국어로 작성하세요.
중요: 답변은 간결하고 명확하게 작성하세요. 가능하면 핵심 내용을 3~5문장 이내로 요약하십시오. 불필요한 부연 설명은 피하세요.
"""
```
> *특히 "3~5문장 이내 요약" 지침을 추가하여, 구구절절한 답변으로 인한 속도 저하를 막았습니다.*

---

## 💻 Phase 4: Streamlit 아키텍처 전환 & UI/UX (Application)

초기에는 FastAPI(백엔드) + Next.js(프론트엔드) 구조였으나, 1인 개발/유지보수의 효율성과 Python 생태계와의 호환성을 고려하여 **Streamlit 단일 앱**으로 전면 리팩토링했습니다.

### 4.1 주요 UI 기능 구현
사용자의 실제 사용 패턴을 고려하여 기능을 배치했습니다.

1.  **사이드바 문서 관리**:
    -   `st.sidebar`에 문서 검색 및 다중 선택 기능을 구현 (`st.multiselect` 등 활용).
    -   선택된 문서가 없으면 자동으로 '전체 문서'를 대상으로 하도록 로직 처리.

2.  **답변 길이 조절 (Slider)**:
    -   `st.select_slider` 사용.
    -   [상세 - 보통 - 요약 - 초요약] 4단계로 나누어, `rag.py`에 전달되는 시스템 프롬프트 지시문을 동적으로 변경.

3.  **🚀 고속 모드 (Fast Mode)**:
    -   `st.toggle` 사용.
    -   사용자가 속도를 원할 경우, 무거운 **Re-ranking 단계를 생략**하고 1차 검색 결과(Vector+BM25)를 바로 사용하도록 분기 처리.
    -   *효과: 응답 시간 40초대 -> 3초대로 단축.*

4.  **실시간 스트리밍 (Streaming)**:
    -   `st.write_stream` 대신 직접 제너레이터(`yield`)를 구현하여 타자 치듯 글자가 나오는 효과 적용.
    -   `time` 모듈을 이용해 답변 생성 소요 시간을 측정하고 투명도(Opacity) 스타일로 하단에 표시.

---

## 🚀 Phase 5: 인프라 및 배포 (Deployment)

### 5.1 실행 환경 자동화 (`Makefile`)
복잡한 가상환경(`python -m venv`) 설정과 패키지 설치(`pip install`) 과정을 단 하나의 명령어로 압축했습니다.

```bash
# Makefile
run:
	python3 -m venv .venv
	.venv/bin/pip install -r requirements.txt
	.venv/bin/streamlit run app.py
```
> 사용자는 터미널에 `make run`만 입력하면 모든 준비가 끝납니다.

---

## 🔍 요약 (Summary)

이 프로젝트는 단순한 "질문하면 답하는 봇"을 넘어, **'정확도'와 '속도'라는 상충되는 두 가치를 사용자가 직접 제어(Control)**할 수 있도록 설계되었습니다.

-   **정확도 필요 시**: 기본 모드 (Hybrid Search + Re-ranking)
-   **속도 필요 시**: 고속 모드 (Skip Re-ranking) + 초요약 모드 (Prompt Tuning)

이러한 유연한 아키텍처는 향후 문서가 수천 개로 늘어나더라도 확장성 있게 대응할 수 있는 기반이 됩니다.

import os
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# 1. ì„¤ì • ë¡œë“œ
load_dotenv()
DB_PATH = "./rfp_database"

# 2. DB ë° ê²€ìƒ‰ê¸°(Retriever) ì„¤ì •
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
if not os.path.exists(DB_PATH):
    print(f"âŒ ì—ëŸ¬: '{DB_PATH}'ê°€ ì—†ìŠµë‹ˆë‹¤. main.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
    exit()

# DB ë¶ˆëŸ¬ì˜¤ê¸°
vectordb = Chroma(persist_directory=DB_PATH, embedding_function=embeddings)
# ê²€ìƒ‰ê¸° ìƒì„± (ìœ ì‚¬ë„ ë†’ì€ ë¬¸ì„œ 3ê°œë¥¼ ê°€ì ¸ì˜¤ë„ë¡ ì„¤ì •)
retriever = vectordb.as_retriever(search_kwargs={"k": 3})

# 3. í”„ë¡¬í”„íŠ¸(ì§€ì‹œì‚¬í•­) ë§Œë“¤ê¸°
# system: AIì—ê²Œ ì—­í• ì„ ë¶€ì—¬í•©ë‹ˆë‹¤.
# human: ì‹¤ì œ ì§ˆë¬¸ê³¼ ê²€ìƒ‰ëœ ë¬¸ë§¥(context)ì„ ë„£ì–´ì¤ë‹ˆë‹¤.
template = """
ë‹¹ì‹ ì€ 'ì œì•ˆìš”ì²­ì„œ(RFP) ì „ë¬¸ê°€'ì…ë‹ˆë‹¤. 
ì•„ë˜ì˜ [ë¬¸ë§¥(Context)]ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•´ ëª…í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”.
ë§Œì•½ ë¬¸ë§¥ì— ì—†ëŠ” ë‚´ìš©ì´ë¼ë©´ "ì œê³µëœ ë¬¸ì„œì—ëŠ” í•´ë‹¹ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ì†”ì§í•˜ê²Œ ë§í•´ì£¼ì„¸ìš”.

[ë¬¸ë§¥(Context)]:
{context}


ì§ˆë¬¸: {question}
"""
prompt = ChatPromptTemplate.from_template(template)

# 4. LLM(ë‘ë‡Œ) ì„¤ì •
model = ChatOpenAI(model="gpt-5-mini", temperature=0)

# 5. ë¬¸ì„œ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ í•©ì¹˜ëŠ” í•¨ìˆ˜
def format_docs(docs):
    return "\n\n".join([d.page_content for d in docs])

# 6. RAG ì²´ì¸ ì—°ê²° (ê²€ìƒ‰ -> í”„ë¡¬í”„íŠ¸ -> LLM -> ë‹µë³€ì¶œë ¥)
rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | model
    | StrOutputParser()
)

# --- [ì‹¤ì œ ì‹¤í–‰ ë¶€ë¶„] ---
if __name__ == "__main__":
    print("ğŸ¤– AIì—ê²Œ ì§ˆë¬¸ì„ ë˜ì§€ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
    
    # ì§ˆë¬¸ ì…ë ¥
    question = "ì œì•ˆì„œ í‰ê°€ ë°©ë²•ì€ ì–´ë–»ê²Œ ë¼?"
    print(f"â“ ì§ˆë¬¸: {question}\n")
    
    # ë‹µë³€ ìƒì„±
    response = rag_chain.invoke(question)
    
    print("âœ… AI ë‹µë³€:")
    print("-" * 50)
    print(response)
    print("-" * 50)